{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cde55a8-b245-482f-89cd-e56b1906d740",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "#### The approximate number system (ANS) is a cognitive system that non-verbally estimates the numerousness, which gives individuals an immediate and intuitive sense for numbers and their association. It is generated by intraparietal sulcus neurons and area lateral intraparietal cortex neurons, and its acuity can be measured using the Weber fraction. The value of the Weber fraction for an individual gives a preciseness of their approximate number sense, i.e. a lower fraction indicates better acuity.\n",
    "\n",
    "#### Sex differences for memory have been uncovered in a study by Loprinzi and Frith in 2018 that generally, female superiority exists in both episodic and object location memory. Cross national studies suggest that although no sex differences are observed in innate mathematical abilities, males tend to have a better performance in mathematical reasoning ability due to environmental influences. A male advantage of spatial abilities is also found to be significant in a recent study conducted by Tsigemen et al, likely due to a more intricate neurocognitive system in males that supports three-dimensional space navigation. In contrast, no significant sex differences were observed for approximate number sense. Therefore, the second hypothesis for this investigation is that there is a significant sex difference in scores of the math, memory, and spatial ability tests, and not a significant sex difference in the scores of the ANS test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77de697-7057-437a-b9a0-22b765746f1e",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Approximate Number Sense (ANS) Test\n",
    "\n",
    "#### For the ANS Test, a global dictionary 'outcome' is created to store all the data recorded in this test. Before the test, the user is asked for anonymous ID and sex, which are added to 'outcome' after clicking the 'Submit' button using the code shown in Fig 1.1.\n",
    "\n",
    "```python\n",
    "# Store user credentials inside the global dictionary\n",
    "if test_info[\"choice\"] == \"Submit\":\n",
    "    outcome[\"user_id\"] = user_id.value\n",
    "    outcome[\"sex\"] = user_sex.value\n",
    "    box.children = []\n",
    "    time.sleep(1)\n",
    "    return outcome, box\n",
    "```\n",
    "##### Fig 1.1 The code for storing ID and sex to 'outcome'.\n",
    "\n",
    "#### The anonymous ID records a test taken. It is used instead of the user's name to limit bias to this investigation. User's sex is selected using toggle buttons (Fig 1.2) to ensure only desired responses are collected, and is linked to their test results to analyze the sex difference observed in the ANS scores.\n",
    "\n",
    "![Toggle buttons for selecting sex.](photos_for_report/1.2.png)\n",
    "##### Fig 1.2 Toggle buttons for selecting sex\n",
    "\n",
    "\n",
    "#### Next, test instructions and a ‘Start’ button to run the test is shown on screen (Fig 1.3). This prepares the user for the test and limits data inaccuracy caused by unfamiliarity of the fast-rolling test trials, so results can be more representative.\n",
    "\n",
    "![Keywords are bolded to stand out to the user](photos_for_report/1.3.png)\n",
    "##### Fig 1.3 Keywords are bolded to stand out to the user\n",
    "\n",
    "#### During the test, a for loop goes through each image code (f'i{n}', n in range of 1-65) in a randomly shuffled list. It opens the image, clears it after 0.75s, then displays 2 buttons (Fig. 1.4). On button click or 3s has passed, whichever earlier, the buttons are cleared to prevent further response and enter the 1.5s intertrial interval (Fig 1.5).\n",
    "\n",
    "![Keywords are bolded to stand out to the user](photos_for_report/1.4A.png)\n",
    "##### Fig 1.4 An example test image and the buttons for which side contains more dots.\n",
    "\n",
    "![Keywords are bolded to stand out to the user](photos_for_report/1.5B.png)\n",
    "##### Fig 1.5 Panel 1 contains the buttons with descriptions 'Left' and 'Right'. By changing its display, the buttons can appear and disappear.\n",
    "\n",
    "#### If the user clicks within 3s, the button's description is checked to see if it is a correct choice (Fig 1.6). The number of correct / wrong responses for the ratio of the image and for total increases by 1, and the total number of responses increases by 1. If the user doesn't click within 3s, this trial is considered invalid because they took longer than an usual instinct to respond, and this trial is excluded from result collection.\n",
    "\n",
    "![Fig 1.6 The if functions to obtain the key results from a button click. 'u' is the image code.](photos_for_report/1.5B.png)\n",
    "##### Fig 1.6 The if functions to obtain the key results from a button click. 'u' is the image code.\n",
    "\n",
    "#### The results from the test include the correct rates for the ratios used to generate the images, the raw data of total correct and wrong answers, the rate of correct answers as the ANS score, and the time taken to complete the test. Fig 1.7 shows how the results are recorded.\n",
    "\n",
    "![Fig 1.7 Data are calculated and their key:value pairs are added to the 'outcome' dictionary.](photos_for_report/1.7.png)\n",
    "##### Fig 1.7 Data are calculated and their key:value pairs are added to the 'outcome' dictionary.\n",
    "\n",
    "#### Finally, the user is asked for consent to upload all results to google form. If the user gives consent, the values of 'outcome' will be uploaded (Fig 1.8).\n",
    "##### ![The function to upload user's results to the google form upon consent.](photos_for_report/1.8.png)\n",
    "\n",
    "## Mathematics Abilities Test\n",
    "## [to be completed] \n",
    "\n",
    "## Memory Test\n",
    "#### The data was collected to pre-made google forms, later viewed in editing mode (hence, /formResponse)\n",
    "![Fig 1.9](photos_for_report/1.7.png)\n",
    "##### Fig 1.9\n",
    "\n",
    "#### What data was collected: \n",
    "#### Initially inputs of the potential answers (words). Too complex to analyse due to diversity of inputs (eg box no. 2 = second = middle). This and aiming for more user-friendly environment led to implementation of widgets (dropdown and radiobuttons - multiple choices for the colors/shapes/positions/sizes).\n",
    "#### Why this data: \n",
    "#### Example: \n",
    "#### Target samples: BIOS0030 module students, males and females aged between 19-22 (controlled variable), same educational background)\n",
    "\n",
    "## Spatial Test (Szymon) \n",
    "## [to be completed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd06239-c669-4201-ad08-89414cb6f015",
   "metadata": {},
   "source": [
    "# Results \n",
    "\n",
    "## ANS and other cognitive tests \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d5c7e-e809-46eb-b09c-7ca9f315719d",
   "metadata": {},
   "source": [
    "| Test    | Mean Score Male | Standard Error Male | Mean Score Female | Standard Error Female | Difference in Score | P-Value (Bonferroni corrected) |\n",
    "|---------|-----------------|---------------------|-------------------|-----------------------|---------------------|--------------------------------|\n",
    "| Spatial | 0.700           | 0.073               | 0.609             | 0.059                 | 0.091               | 1.000                          |\n",
    "| Memory  | 0.385           | 0.042               | 0.457             | 0.041                 | -0.072              | 1.000                          |\n",
    "| Math    | 0.849           | 0.034               | 0.877             | 0.022                 | -0.028              | 1.000                          |\n",
    "| Ans     | 0.558           | 0.025               | 0.535             | 0.030                 | 0.023               | 1.000                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69361d28-0e0c-4a40-abda-838bd2bb1743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
